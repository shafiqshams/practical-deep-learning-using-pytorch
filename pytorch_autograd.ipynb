{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxib/kcIdP9cdaGRoBRSqS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shafiqshams/practical-deep-learning-using-pytorch/blob/main/pytorch_autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AdwZ8Z1CkgQL"
      },
      "outputs": [],
      "source": [
        "# creating manual func without using autograd\n",
        "# calculating derivative of y w.rt. x\n",
        "# Write a program to calculate dy/dx for any given value of x\n",
        "def dy_dx(x):\n",
        "  return 2*x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dy_dx(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK6R8dpepJdW",
        "outputId": "dfaa29e6-3470-4722-8359-c361c834fed7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def dz_dx(x):\n",
        "  return 2 * x * math.cos(x**2)"
      ],
      "metadata": {
        "id": "O2kRfGwOv9mw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dz_dx(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHxvK-_YwKEZ",
        "outputId": "6f8f0af3-4af3-4e98-8cf9-e77b0f49dcf2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-5.466781571308061"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### What is Autograd?\n",
        "\n",
        " Autograd is a core component of PyTorch that provides automatic differentiation for tensor operations. It enables gradient computation, which is essential for training machine learning models using optimization algorithms like gradient descent."
      ],
      "metadata": {
        "id": "37zeLkALwmz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate dy/dx for any give x, with the help of autograd\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "qgHrMJhwwowl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a tensor with grad set to true\n",
        "# because of this pytorch understands we want to calc derivative of it\n",
        "x = torch.tensor(3.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "pVjALCTTwpYw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2"
      ],
      "metadata": {
        "id": "fpT7Bt64zmSY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYbZ5D5ez03o",
        "outputId": "1241c62a-f697-42e1-fbd5-f17c08544289"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcyE3etiz1sp",
        "outputId": "835e11bb-071f-4e41-bff9-f05b218a2577"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9., grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "R77baaVbz2SF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7il32jm0CvK",
        "outputId": "c3f91668-f423-4b62-b655-888e3e3f4755"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(3.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "m4LKR-tr1TjH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = a**2"
      ],
      "metadata": {
        "id": "XyAxZKCN1VXX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.sin(b)"
      ],
      "metadata": {
        "id": "WspLwZZ81Wy3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a computational graph:\n",
        "\n",
        "\n",
        "![]()\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1fyPduolB7gMhF7Hv7uAeWtk6vi_Yjxux\" alt=\"Computational Graph\" width=\"80%\" height=\"60%\">\n"
      ],
      "metadata": {
        "id": "QEe42Ek2107O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c.backward()"
      ],
      "metadata": {
        "id": "uzXyTX7o1awI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duUZQR1N1bxn",
        "outputId": "36daee3a-39cb-4a18-8d7f-b3f958c97fb7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-5.4668)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we cannot calc the grad of intermediate nodes.\n",
        "# input tensors: leaves node\n",
        "# output tensors: root node\n",
        "# more details here: https://docs.pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#more-on-computational-graphs\n",
        "b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofKAbluQ1yj9",
        "outputId": "ae343d6e-a0c8-49fd-8acf-54b509828bdd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2110846228.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
            "  b.grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VtMSI4VD4-bq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}