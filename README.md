# ğŸ§  Practical Deep Learning Using PyTorch

A hands-on and evolving collection of **PyTorch notebooks** focused on understanding and implementing deep learning concepts from the ground up.  

The repository starts with the fundamentals â€” **tensors**, the core data structure in PyTorch â€” and will expand over time to include more advanced topics like autograd, neural networks, optimization, and model deployment.

---

## ğŸ“˜ Current Notebook

### [`tensors-in-pytorch.ipynb`](./tensors-in-pytorch.ipynb)

An introductory **Google Colab** notebook exploring the core building block of PyTorch â€” **tensors**.  
It demonstrates how to create, manipulate, and perform mathematical operations on tensors, while also covering NumPy interoperability and GPU support.

#### ğŸ§© Topics Covered
- Import torch and GPU availability check
- Creating tensors using multiple methods  
- Inspecting tensor shapes and data types  
- Reshaping, cloning, and copying tensors  
- Scalar, element-wise, matrix, and reduction operations  
- Comparison and in-place operations  
- Conversion between **NumPy** and **PyTorch**  

---

## ğŸš€ Quick Example

```python
import torch
import numpy as np

# Check GPU availability
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Running on: {device}")

# Create a tensor
t = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32).to(device)

# NumPy â†” PyTorch conversion
arr = t.cpu().numpy()
t2 = torch.from_numpy(arr)

# Operations
print(t + t2)       # Element-wise add
print(t.mean())     # Reduction op
print(t.reshape(4, 1))  # Reshape
```

## ğŸ§­ Roadmap

This repository will gradually expand with more notebooks covering:

- **Autograd and gradient computation**  
- **Neural network layers and models**  
- **Loss functions and optimizers**  
- **Training pipelines and evaluation**  
- **GPU acceleration and performance tuning**  
- **Model saving, loading, and deployment**


ğŸ’¡ Goal
-------

To build a solid foundation in **deep learning and neural networks** by learning through **hands-on implementation, experimentation, and practical projects**.

ğŸ¤ Contributions
----------------

This is primarily a learning repository, but suggestions and discussions are always welcome!

ğŸ“« Contact
----------

If youâ€™d like to connect or collaborate, feel free to reach out via [LinkedIn](https://www.linkedin.com/in/shafiqshams) or open an issue/discussion.

> _"The best way to learn is by doing â€” and breaking things along the way."_ ğŸš§
